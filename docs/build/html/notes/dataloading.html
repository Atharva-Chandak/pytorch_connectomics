

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Data Loading &mdash; connectomics latest documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Neuron Segmentation" href="../tutorials/snemi.html" />
    <link rel="prev" title="Configurations" href="config.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #FFFFFF" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/logo_text.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                latest
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="config.html">Configurations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="config.html#basic-usage">Basic Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="config.html#multiple-losses-for-a-single-learning-target">Multiple Losses for a Single Learning Target</a></li>
<li class="toctree-l2"><a class="reference internal" href="config.html#multitask-learning">Multitask Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="config.html#inference">Inference</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Data Loading</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#data-augmentation">Data Augmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rejection-sampling">Rejection Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tiledataset">TileDataset</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/snemi.html">Neuron Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/mito.html">Mitochondria Segmentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/mito.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/mito.html#semantic-segmentation">Semantic Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/mito.html#instance-segmentation">Instance Segmentation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/synapse.html">Synapse Detection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/synapse.html#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/synapse.html#synaptic-cleft-detection">Synaptic Cleft Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/synapse.html#synaptic-polarity-detection">Synaptic Polarity Detection</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/datasets.html">connectomics.data.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/augmentation.html">connectomics.data.augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/engine.html">connectomics.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/model.html">connectomics.model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules/model.html#module-connectomics.model.block">Building Blocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/model.html#module-connectomics.model.zoo">Model Zoo</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/utils.html">connectomics.utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules/utils.html#module-connectomics.utils.processing">Post-processing</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">connectomics</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Data Loading</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notes/dataloading.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="data-loading">
<h1>Data Loading<a class="headerlink" href="#data-loading" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#data-augmentation" id="id1">Data Augmentation</a></p></li>
<li><p><a class="reference internal" href="#rejection-sampling" id="id2">Rejection Sampling</a></p></li>
<li><p><a class="reference internal" href="#tiledataset" id="id3">TileDataset</a></p></li>
</ul>
</div>
<div class="section" id="data-augmentation">
<h2><a class="toc-backref" href="#id1">Data Augmentation</a><a class="headerlink" href="#data-augmentation" title="Permalink to this headline">¶</a></h2>
<p>Since many semi-supervised and unsupervised learning tasks do not require labels, the only key required in our
data augmentor is <code class="docutils literal notranslate"><span class="pre">'image'</span></code>. Let’s look at an example for using an augmentation pipeline on input images:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">connectomics.data.augmentation</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">tranforms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Rescale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.8</span><span class="p">),</span>
    <span class="n">MisAlignment</span><span class="p">(</span><span class="n">displacement</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                 <span class="n">rotate_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">CutBlur</span><span class="p">(</span><span class="n">length_ratio</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
            <span class="n">down_ratio_min</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span>
            <span class="n">down_ratio_max</span><span class="o">=</span><span class="mf">8.0</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">),</span>
<span class="p">]</span>
<span class="n">augmentor</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="n">tranforms</span><span class="p">,</span>
                    <span class="n">input_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>

<span class="n">sample</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">image</span><span class="p">}</span>
<span class="n">augmented</span> <span class="o">=</span> <span class="n">augmentor</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
<p>Then the augmented data can be retrived using the corresponding key. Our augmentor can also apply the same set
of transformations to the input images and all other specified targets. For example, under the supervised
segmentation setting, an label image/volume contains the segmentation masks and a valid mask indicating the
annotated regions are required. We provide the <code class="docutils literal notranslate"><span class="pre">additional_targets</span></code> option to handle those targets:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">connectomics.data.augmentation</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">additional_targets</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;mask&#39;</span><span class="p">,</span>
                      <span class="s1">&#39;valid_mask&#39;</span><span class="p">:</span> <span class="s1">&#39;mask&#39;</span><span class="p">}</span>

<span class="n">tranforms</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Rescale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
            <span class="n">additional_targets</span><span class="o">=</span><span class="n">additional_targets</span><span class="p">),</span>
    <span class="n">MisAlignment</span><span class="p">(</span><span class="n">displacement</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                 <span class="n">rotate_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">additional_targets</span><span class="o">=</span><span class="n">additional_targets</span><span class="p">),</span>
    <span class="n">CutBlur</span><span class="p">(</span><span class="n">length_ratio</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
            <span class="n">down_ratio_min</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span>
            <span class="n">down_ratio_max</span><span class="o">=</span><span class="mf">8.0</span><span class="p">,</span>
            <span class="n">p</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
            <span class="n">additional_targets</span><span class="o">=</span><span class="n">additional_targets</span><span class="p">),</span>
<span class="p">]</span>
<span class="n">augmentor</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">(</span><span class="n">tranforms</span><span class="p">,</span>
                    <span class="n">input_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
                    <span class="n">additional_targets</span><span class="o">=</span><span class="n">additional_targets</span><span class="p">)</span>

<span class="n">sample</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span>
          <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span>
          <span class="s1">&#39;valid_mask&#39;</span><span class="p">:</span> <span class="n">valid_mask</span><span class="p">}</span>
<span class="n">augmented</span> <span class="o">=</span> <span class="n">augmentor</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Each addition target need to be specified with a name (<em>e.g.</em>, <code class="docutils literal notranslate"><span class="pre">'valid_mask'</span></code>) and a target type (<code class="docutils literal notranslate"><span class="pre">'img'</span></code> or <code class="docutils literal notranslate"><span class="pre">'mask'</span></code>). Some augmentations are only
applied to <code class="docutils literal notranslate"><span class="pre">'img'</span></code>, and augmentations for both <code class="docutils literal notranslate"><span class="pre">'img'</span></code> and <code class="docutils literal notranslate"><span class="pre">'mask'</span></code> will use different interpolation modes for them.</p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">'label'</span></code> key in <code class="docutils literal notranslate"><span class="pre">'mask'</span></code> target type is used by default in the configuration file as most of the tutorial examples belong to the supervised
training category. For model training with partially annotated dataset under the supervised setting, we need to add:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">AUGMENTOR</span><span class="p">:</span>
  <span class="nt">ADDITIONAL_TARGETS_NAME</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;label&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;valid_mask&#39;</span><span class="p p-Indicator">]</span>
  <span class="nt">ADDITIONAL_TARGETS_TYPE</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;mask&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;mask&#39;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>Each transformation class is associated with an <code class="docutils literal notranslate"><span class="pre">ENABLED</span></code> key. To turn off a specific transformation (<em>e.g.</em>, mis-alignment), set:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">AUGMENTOR</span><span class="p">:</span>
  <span class="nt">MISALIGNMENT</span><span class="p">:</span>
    <span class="nt">ENABLED</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span>
</pre></div>
</div>
</div>
<div class="section" id="rejection-sampling">
<h2><a class="toc-backref" href="#id2">Rejection Sampling</a><a class="headerlink" href="#rejection-sampling" title="Permalink to this headline">¶</a></h2>
<p>Rejection sampling in the dataloader is applied for the following two purposes:</p>
<ol class="arabic simple">
<li><p><strong>Adding more attention to sparse targets</strong>:</p></li>
</ol>
<p>For some datasets/tasks, the foreground mask is sparse in the volume (<em>e.g.</em>, <a class="reference external" href="https://zudi-lin.github.io/pytorch_connectomics/build/html/tutorials/synapse.html#introduction">synapse detection</a>).
Therefore we perform reject sampling to decrease the ratio of (all completely avoid) regions without foreground pixels.
Such a design lets the model pay more attention to the foreground pixels to alleviate false negatives (but may introduce
more false positives). There are two corresponding hyper-parameters in the configuration file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">DATASET</span><span class="p">:</span>
    <span class="nt">REJECT_SAMPLING</span><span class="p">:</span>
    <span class="nt">SIZE_THRES</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
    <span class="nt">P</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.95</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">SIZE_THRES:</span> <span class="pre">1000</span></code> key-value pair means that if a random volume contains more than 1,000 non-background voxels, then
the volume is considered as a foreground volume and is returned by the rejection sampling function. If it contains less
than 1,000 voxels, the function will reject it with a probability <code class="docutils literal notranslate"><span class="pre">P:</span> <span class="pre">0.95</span></code> and sample another volume. <code class="docutils literal notranslate"><span class="pre">SIZE_THRES</span></code> is
set to -1 by default to disable the rejection sampling.</p>
<ol class="arabic simple" start="2">
<li><p><strong>Handling partially annotated data</strong>:</p></li>
</ol>
<p>Some datasets are only partially labeled, and the unlabeled region should not be considered in loss calculation. In that case,
the user can specify the data path to the valid mask using the <code class="docutils literal notranslate"><span class="pre">DATASET.VALID_MASK_NAME</span></code> option. The valid mask volume should
be of the same shape as the label volume with non-zero values denoting annotated regions. A sampled volume with a valid ratio
less than 0.5 will be rejected by default.</p>
</div>
<div class="section" id="tiledataset">
<h2><a class="toc-backref" href="#id3">TileDataset</a><a class="headerlink" href="#tiledataset" title="Permalink to this headline">¶</a></h2>
<p>Large-scale volumetric datasets (<em>e.g.,</em> <a class="reference external" href="https://mitoem.grand-challenge.org">MitoEM</a>) are usually stored as individual
tiles (<em>i.e.</em>, 2D patches). Directly loading them as a single array into the memory for training and inference is infeasible.
Therefore we designed the <a class="reference internal" href="../modules/datasets.html#connectomics.data.dataset.TileDataset" title="connectomics.data.dataset.TileDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">connectomics.data.dataset.TileDataset</span></code></a> class that reads the paths of the tiles and
construct tractable chunks for processing. To use this dataset class, the user needs to prepare a <cite>JSON</cite> file which contains
the information of the dataset. An example for the MitoEM dataset can be
found <a class="reference external" href="https://raw.githubusercontent.com/zudi-lin/pytorch_connectomics/master/configs/MitoEM/im_train.json">here</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tutorials/snemi.html" class="btn btn-neutral float-right" title="Neuron Segmentation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="config.html" class="btn btn-neutral float-left" title="Configurations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2021, Zudi Lin and Donglai Wei

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
  
    <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
      <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Read the Docs</span>
        v: latest
        <span class="fa fa-caret-down"></span>
      </span>
      <div class="rst-other-versions">
        <dl>
          <dt>Versions</dt>
          
            <dd><a href="#">latest</a></dd>
          
        </dl>
        <dl>
          <dt>Downloads</dt>
          <dd><a href="https://github.com/zudi-lin/pytorch_connectomics/tree/master/docs/build/pdf/connectomics.pdf">PDF</a></dd>
          <dd><a href="https://github.com/zudi-lin/pytorch_connectomics/tree/master/docs/build/html">HTML</a></dd>
        </dl>
        <dl>
          <dt>On Github</dt>
          <dd><a href="https://github.com/zudi-lin/pytorch_connectomics">Home</a></dd>
          <dd><a href="https://github.com/zudi-lin/pytorch_connectomics/tree/master/docs">Docs</a></dd>
        </dl>
      </div>
    </div>
  


</body>
</html>