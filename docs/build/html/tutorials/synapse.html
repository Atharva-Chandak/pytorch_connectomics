



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Synapse Detection &mdash; connectomics latest documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.svg"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/css/pytc-theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@1.0.0-alpha.28/dist/style.min.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="connectomics.data" href="../modules/data.html" />
    <link rel="prev" title="Mitochondria Segmentation" href="mito.html" /> 

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">

    <a class="header-logo" href="https://zudi-lin.github.io/pytorch_connectomics/build/html/index.html" aria-label="PyTorch"></a>

    <div class="header-container">

      <div class="main-menu">
        <ul>
          <li>
            <a href="../index.html">Get Started</a>
          </li>
          <li>
            <a href="snemi.html">Tutorials</a>
          </li>
          <li>
            <a href="../index.html">Docs</a>
          </li>
          <li>
            <a href="https://github.com/zudi-lin/pytorch_connectomics/tree/master">Github</a>
          </li>
          <li>
            <a href="../about.html">About Us</a>
          </li>

        </ul>
      </div>

      <!-- <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a> -->
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  latest
                </div>
              
            

            <div id="docsearch"></div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/config.html">Configurations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notes/dataloading.html">Data Loading</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="neuron.html">Neuron Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mito.html">Mitochondria Segmentation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Synapse Detection</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/data.html">connectomics.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/engine.html">connectomics.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/model.html">connectomics.model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/utils.html">connectomics.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">Team</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about/team.html">About Us</a></li>
</ul>

            
          
        </div>
      </div>

      


    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Synapse Detection</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/synapse.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="synapse-detection">
<h1>Synapse Detection<a class="headerlink" href="#synapse-detection" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>A <a class="reference external" href="https://en.wikipedia.org/wiki/Synapse">synapse</a> is an essential structure in the nervous system that allows an electric or chemical signal to be
passed to another neuron or an effector cell (<em>e.g.</em>, muscle fiber). Identification of synapses is important for reconstructing the wiring diagram of
neurons to enable new insights into the workings of the brain, which is the long-term goal of the connectomics area. Signal flows in one direction
at a synapse, therefore each synapse usually consists of a pre-synaptic region and a post-synaptic region.</p>
<p>This tutorial has two parts. In the first part, you will learn how to detect <strong>synaptic clefts</strong> by predicting the synaptic cleft pixels on the
<a class="reference external" href="https://cremi.org">CREMI Challenge</a> dataset from adult <em>Drosophila melanogaster</em> brain tissue. This dataset is released in 2016. In the second part,
you will learn how to predict the <strong>synaptic polarity masks</strong> to demonstrate the signal flow between neurons using the dataset released
by <a class="reference external" href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630103.pdf">Lin et al.</a> in 2020. The brain sample is collected from Layer II/III in
the primary visual cortex of an adult rat.</p>
</div>
<div class="section" id="synaptic-cleft-detection">
<h2>Synaptic Cleft Detection<a class="headerlink" href="#synaptic-cleft-detection" title="Permalink to this headline">¶</a></h2>
<p>This tutorial provides step-by-step guidance for synaptic cleft detection with <a class="reference external" href="https://cremi.org">CREMI</a> benchmark datasets.
We consider the task as a semantic segmentation task and predict the synapse pixels with encoder-decoder ConvNets similar to
the models used in affinity prediction in <a class="reference external" href="https://zudi-lin.github.io/pytorch_connectomics/build/html/tutorials/snemi.html">neuron segmentation</a>.
The evaluation of the synapse detection results is based on the F1 score and average distance. See <a class="reference external" href="https://cremi.org/metrics/">CREMI metrics</a>
for more details.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We preform re-alignment of the original CREMI image stacks and also remove the crack artifacts. Please reverse
the alignment before submitting the test prediction to the CREMI challenge.</p>
</div>
<p>Script needed for this tutorial can be found at <code class="docutils literal notranslate"><span class="pre">pytorch_connectomics/scripts/</span></code>. The <em>YAML</em> configuration files can be found at <code class="docutils literal notranslate"><span class="pre">pytorch_connectomics/configs/</span></code>, which
stores the common settings for model training and inference. Other default configuration options can be found at <code class="docutils literal notranslate"><span class="pre">pytorch_connectomics/connectomics/config/</span></code>. The pytorch
dataset class of the synaptic cleft detection task is <a class="reference internal" href="../modules/data.html#connectomics.data.dataset.VolumeDataset" title="connectomics.data.dataset.VolumeDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">connectomics.data.dataset.VolumeDataset</span></code></a>.</p>
<div class="figure align-center" id="id1">
<a class="reference internal image-reference" href="../_images/cremi_qual.png"><img alt="../_images/cremi_qual.png" src="../_images/cremi_qual.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text">Qualitative results of the synaptic cleft prediction (red segments) on the CREMI challenge test volumes. The three images from left to right are
cropped from volume A+, B+, and C+, respectively.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<ol class="arabic">
<li><p>Get the dataset:</p>
<blockquote>
<div><p>Download the dataset from the Harvard RC server:</p>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>wget http://rhoana.rc.fas.harvard.edu/dataset/cremi.zip
</pre></div>
</div>
</div></blockquote>
<p>For description of the data please check <a class="reference external" href="https://vcg.github.io/newbie-wiki/build/html/data/data_em.html">this page</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you use the original CREMI challenge datasets or the data processed by yourself, the file names can be
different from the default ones. In such case, please change the corresponding entries, including <code class="docutils literal notranslate"><span class="pre">IMAGE_NAME</span></code>,
<code class="docutils literal notranslate"><span class="pre">LABEL_NAME</span></code> and <code class="docutils literal notranslate"><span class="pre">INPUT_PATH</span></code> in the <a class="reference external" href="https://github.com/zudi-lin/pytorch_connectomics/blob/master/configs/CREMI-Synaptic-Cleft.yaml">CREMI config file</a>.</p>
</div>
</div></blockquote>
</li>
<li><p>Run the main.py script for training. This script can take a list of volumes and conduct training/inference at the same time.</p>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ source activate py3_torch
$ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -u scripts/main.py \
  --config-file configs/CREMI-Synaptic-Cleft.yaml
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">config-file</span></code>: configuration setting for the current experiment.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Visualize the training progress:</p>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ tensorboard --logdir runs
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Run the main.py script for inference:</p>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -u scripts/main.py \
  --config-file configs/CREMI-Synaptic-Cleft.yaml \
  --checkpoint outputs/CREMI_syn_baseline/volume_50000.pth.tar \
  --inference
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">config-file</span></code>: configuration setting for current experiments.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">inference</span></code>: will run inference when given, otherwise will run training instead.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">checkpoint</span></code>: the pre-trained checkpoint file for inference.</p></li>
</ul>
</div></blockquote>
</li>
</ol>
</div>
<div class="section" id="synaptic-polarity-detection">
<h2>Synaptic Polarity Detection<a class="headerlink" href="#synaptic-polarity-detection" title="Permalink to this headline">¶</a></h2>
<p>This tutorial provides step-by-step guidance for synaptic polarity detection with the EM-R50 dataset released by <a class="reference external" href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123630103.pdf">Lin et al.</a> in 2020.
This task is different from the synaptic cleft detection task in two aspects. First, this one requires distinguishing different synapses, while the cleft detection task
only needs the binary foreground mask for evaluation. Second, the polarity detection task also requires separated pre-synaptic and post-synaptic masks.
The evaluation metric of the synaptic polarity detection results is an IoU-based F1 score. The sparsity and diversity of synapses make the task challenging.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We tackle the task using a bottom-up approach that first generates the segmentation masks of synaptic regions and then apply post-processing algorithms like
connected component labeling to separate individual synapses. Our segmentation model uses a model target of three channels. The three channels
are <strong>pre-synaptic region</strong>, <strong>post-synaptic region</strong> and <strong>synaptic region</strong> (union of the first two channels), respectively.</p>
</div>
<p>All the scripts needed for this tutorial can be found at <code class="docutils literal notranslate"><span class="pre">pytorch_connectomics/scripts/</span></code>.
The pytorch dataset class of synaptic partners is <a class="reference internal" href="../modules/data.html#connectomics.data.dataset.VolumeDataset" title="connectomics.data.dataset.VolumeDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">connectomics.data.dataset.VolumeDataset</span></code></a>.</p>
<div class="figure align-center" id="id2">
<a class="reference internal image-reference" href="../_images/polarity_qual.png"><img alt="../_images/polarity_qual.png" src="../_images/polarity_qual.png" style="width: 800px;" /></a>
<p class="caption"><span class="caption-text">Qualitative results of the synaptic polarity prediction on the EM-R50 dataset. The three-channel outputs that consist of pre-synaptic region, post-synaptic region and their
union (synaptic region) are visualizd in color on the EM images. The single flows from the magenta sides to the cyan sides between neurons.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<ol class="arabic">
<li><p>Get the dataset:</p>
<blockquote>
<div><p>Download the example dataset for synaptic polarity detection from our server:</p>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>wget http://rhoana.rc.fas.harvard.edu/dataset/jwr15_synapse.zip
</pre></div>
</div>
</div></blockquote>
</div></blockquote>
</li>
<li><p>Run the training script. The training and inference script can take a list of volumes (separated by ‘&#64;’) in either the yaml config file or by command-line arguments.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default the path of images and labels are not specified. To
run the training scripts, please revise the <code class="docutils literal notranslate"><span class="pre">IMAGE_NAME</span></code>, <code class="docutils literal notranslate"><span class="pre">LABEL_NAME</span></code>
and <code class="docutils literal notranslate"><span class="pre">INPUT_PATH</span></code> options in <code class="docutils literal notranslate"><span class="pre">configs/Synaptic-Polarity.yaml</span></code>.
The options can also be given as command-line arguments without changing of the <code class="docutils literal notranslate"><span class="pre">yaml</span></code> configuration files.</p>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ source activate py3_torch
$ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -u scripts/main.py \
  --config-file configs/Synaptic-Polarity.yaml
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We add <strong>higher weights</strong> to the foreground pixels and apply <strong>rejection sampling</strong> to reject samples without synapes during training to heavily penalize
false negatives. This is beneficial for down-stream proofreading and analysis as correcting false positives is much easier than finding missing synapses in the
vast volumes.</p>
</div>
</div></blockquote>
</li>
<li><p>Visualize the training progress. More info <a class="reference external" href="https://vcg.github.io/newbie-wiki/build/html/computation/machine_rc.html">here</a>:</p>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ tensorboard --logdir outputs/synaptic_polarity
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Run inference on image volumes:</p>
<blockquote>
<div><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$ source activate py3_torch
$ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python -u scripts/main.py \
  --config-file configs/Synaptic-Polarity.yaml --inference \
  --checkpoint outputs/synaptic_polarity/volume_xxxxx.pth.tar
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default the path of images for inference are not specified. Please change
the <code class="docutils literal notranslate"><span class="pre">INFERENCE.IMAGE_NAME</span></code> option in <code class="docutils literal notranslate"><span class="pre">configs/Synaptic-Polarity.yaml</span></code>.</p>
</div>
</div></blockquote>
</li>
<li><p>Apply post-processing algorithms. Use the <code class="docutils literal notranslate"><span class="pre">polarity2instance</span></code> function (<a class="reference external" href="https://zudi-lin.github.io/pytorch_connectomics/build/html/modules/utils.html#connectomics.utils.process.polarity2instance">link</a>) to
convert the probability map into instance/semantic segmentation masks based on the application.</p></li>
</ol>
</div>
</div>


             </article>
             
            </div>
            <footer>
    
      <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        
          <a href="../modules/data.html" class="btn btn-neutral float-right" title="connectomics.data" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
        
        
          <a href="mito.html" class="btn btn-neutral" title="Mitochondria Segmentation" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
        
      </div>
    
  
    
  
      <hr>
  
    
  
    <div role="contentinfo">
      <p>
          &copy; Copyright 2019-2021, Zudi Lin and Donglai Wei.
  
      </p>
    </div>
      
        <div>
          Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
        </div>
       
  
  </footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Synapse Detection</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#synaptic-cleft-detection">Synaptic Cleft Detection</a></li>
<li><a class="reference internal" href="#synaptic-polarity-detection">Synaptic Polarity Detection</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Harvard VCG</h2>
          <p>Visual Computing Group at Harvard</p>
          <a class="with-right-arrow" href="https://lichtmanlab.fas.harvard.edu">Harvard VCG</a>
        </div>
        <div class="col-md-4 text-center">
          <h2>Lichtman Lab</h2>
          <p>Lichtman Lab at Harvard</p>
          <a class="with-right-arrow" href="https://lichtmanlab.fas.harvard.edu">Lichtman Lab</a>
        </div>
        <div class="col-md-4 text-center">
          <h2>CBS</h2>
          <p>Center for Brain Science at Harvard</p>
          <a class="with-right-arrow" href="http://cbs.fas.harvard.edu">CBS</a>
        </div>
      </div>
    </div>
  </div>



  <!-- end of commented out for Ignite -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://zudi-lin.github.io/pytorch_connectomics/build/html/index.html" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>
    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>
          <li>
            <a href="#">Features</a>
          </li>
          <li>
            <a href="#">Ecosystem</a>
          </li>
          <li>
            <a href="">Blog</a>
          </li>
          <li>
            <a href="https://zudi-lin.github.io/pytorch_connectomics/build/html/tutorials/snemi.html">Tutorials</a>
          </li>
          <li>
            <a href="https://zudi-lin.github.io/pytorch_connectomics/build/html/index.html">Docs</a>
          </li>
          <li>
            <a href="">Resources</a>
          </li>
          <li>
            <a href="https://github.com/zudi-lin/pytorch_connectomics/tree/master">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    var collapsedSections = ['Notes']
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@docsearch/js@1.0.0-alpha.28/dist/umd/index.min.js"></script>
  <script type="text/javascript">
  let VERSION
  if ('latest'.includes('v')) {
    VERSION = 'latest'
  } else {
    VERSION = 'latest'
  }
  docsearch({
    container: '#docsearch',
    apiKey: '19a7a7a75d87608d6f42c722ed1e293f',
    indexName: 'ignite',
    placeholder: 'Search PyTC Docs',
    searchParameters: {
      'facetFilters': [`version:${VERSION}`],
    }
  });
  </script>
</body>
</html>